%
% File project_checkpoint2.tex
%

\documentclass[11pt,letterpaper]{article}
\usepackage{naaclhlt2016}
\usepackage{times}
\usepackage{latexsym}

\naaclfinalcopy % Uncomment this line for the final submission

\title{Project Checkpoint 2 - Word Sense Disambiguation}

\author{Anthony Zheng, Yang Shi, Liang Zhang, Ruoyu Duan\\
      Word Sense Disambiguation\\
      EECS 595\\
	    University of Michigan\\
	    {\tt \{zhengant, gouzi, johzhang, duanry\}@umich.edu}
}

\date{}

\begin{document}

\maketitle

\section{Project Description}
In our daily life, it is common to see word ambiguous everywhere. From books, news or songs, you can easily notice their existence. We, as the most intelligent creature on earth, always perplex on the ambiguous word meaning we see, not to say how difficult for the machine to understand human language meanings. In Natural Language Processing, it is common to use Word2Vec to represent words to be used in the machine learning or neural network training, however, the word vector uses in machine learning can’t show the difference of its meaning when it is surrounded by different context. We will lose some valuable information to help us achieve better performance on some Natural Language Processing tasks. To be specific, the same word may have different meanings in two different sentences or have different meanings and POS tags in the same sentence. For example: 
\begin{enumerate}
  \item He sat down beside the Seine river \textbf{bank}.\\
  He deposited the money at the Chase \textbf{bank}.
  \item The family was hoping their \textbf{live} plants would \textbf{live}.
  \item After taking a shot with his \textbf{bow}, the archer took a \textbf{bow}. 
\end{enumerate}
By identifying the different word meanings, we can better detect the word sense in an ambiguous situation to help machine better understand the meaning of the context. In this project, our idea is to use unsupervised learning method to train our model to perform predicting the word sense. Our method is to use context to predict the word sense. The first step, we will mine word feature from our datasets download from Google. The second step, we will throw raw text into the unsupervised learning model to cluster word sense based on the context around this word. And the third step is to annotate test data based on our trained model. The last step is to use our predicted result to do evaluation base on the evaluation datasets. We will evaluate how well our  model performs on prediction accuracy. Our goal is to examine the feasibility of our idea on this task and how well our method can perform. The application of Word Sense Disambiguation is valuable to Natural Language Processing task because it can give us more potential information which didn’t give in the raw data. We can preprocess any text data with annotations to each word, then to use this new text to perform any task we interested based on these data. For example, we can try to apply it to sentiment detection, sentence summarization, QA system, etc. Word Sense Disambiguation model may highly improve the performance of the algorithm implemented on these related tasks. 

\section{Related Work}
Lee and Ng \shortcite{lee2002empirical} performed an empirical evaluation of knowledge sources and learning algorithms for word sense disambiguation. In this paper, several interesting preprocessing techniques are introduced like part-of-speech (POS) of neighboring words, single words in the surrounding context, local collocation, syntactics relations, all of which can give us good intuition to do the feature selection and preprocessing. Also, the author provides a variety of learning algorithms including Support Vector Machines, AdaBoost, Naive Bayes, Decision Trees and also some smoothing techniques. In our project, in order to build the word-to-vector input matrix more efficiently, we will take the surrounding context of every training samples (specific words or collocations), which we can refer something from the the preprocessing step of this paper (work).

Yuan et. al. \shortcite{yuan2016semi}, explored an LSTM based supervised WSD model, which is trained on sense supervised unlabeled data and generates context vectors based on previous history. Since the LSTM based supervised ESD model is a very cutting-edge technique, we found that many researchers or teams have used this techniques a lot on the WSD for either the supervised or unsupervised way of learning. I think we can probably use this if we need to improve our own work.

Yarowsky \shortcite{yarowsky1995unsupervised} introduces two methods about how unsupervised word sense disambiguation rivals supervised one. One is called “One sense per collocation”, which uses the nearby words to build the feature vector for the input because they can provide strong and consistent clues to the sense of a target word. Another one is called “One sense per discourse”, which takes advantage of the regularity in conjunction with seperated models of local context. For the rest of the content, the author illustrated full steps of performing an unsupervised learning algorithm by the disambiguation of the given polysemous words. The most existing fact we discovered from this paper is that unsupervised word sense disambiguation rivals supervised one, which really gave us the intuition to use the unsupervised learning.

\section{Data}
For data collection part, the main data we use is ``word sense disambiguation corpera'' from websites of Google AI. The corpera is used especially for training and testing model related to word sense disambiguation. The data is all in xml form. The data is divided into speech part and writing part and each parts contains large data from variety source, which can reduce data bias. Each file is filled with lots of sentences and ambiguous word is tagged with the reference of the position in dictionary. For the same word,by comparing the position in the dictionary, we can know whether the meaning of the word is changed or not.  We also found another helpful dataset: the data of SemEval 2010 Word Sense Induction \& Disambiguation Task. In addition, we found collocation data set to help identifying collocation for possible ambiguous word.

After analyzing the data, we found that it was interesting that for lots of  words which contains multiple meaning, the part of speech among different meaning of a word is different, like ``desert'' has three main meaning and the ``part of speech'' among them are ``noun'', ``verb'', ``adjective'', all are different.

Based on the above finding and other analytic work, for data annotation, we first pos tag all the words. Then,  judge the collocations in each sentences. After that, we performed  word2vec representation of the raw text combined with pos tag as feature extraction. We temperialy decided to use the combination of three words before the target word, the target word, and three words after target word as a unit input for target word. Since we train the model in an unsupervised way, we will not use the gold standard in training. However, we will use the gold standard of the data in evaluation part.

After collecting and annotating the data, then next we will use unsupervised learning model to train and test our dataset.
\section{Methodology}
We plan on taking an unsupervised approach to tackle word sense disambiguation, i.e. the input will be an arbitrary collection of texts. The model pipeline will look something like the following:
\begin{enumerate}
  \item Feature extraction on each word
  \item Clustering instances of each word to determine word sense(s)
  \item Annotating the data to disambiguate different word senses
\end{enumerate}

We describe each of these steps in greater detail in the following subsections, then we describe potential methods for evaluation.

\subsection{Feature Extraction}
The intuition here is that humans can determine word sense based on the context of the word, so we should design our features so that they somehow capture the information contained in the context. Furthermore, we want to eventually run the feature vectors mined for each word through a clustering algorithm so the features should somehow reflect similarity, i.e. feature vectors that are closer together according to some distance metric (e.g. Euclidean distance or cosine similarity) should be more similar in word sense than feature vectors that are further apart. Some sort of vector space model like Word2Vec (the continuous bag-of-words version since we want to generate features based on the context and not the word itself) makes sense as a starting point. 

We may also include features like a part-of-speech tag since different part-of-speech tags can be a good indicator of different word senses. We will want to think about how to best add it to the feature vector so it does not adversely affect the clustering since we still want similar word senses to generate similar feature vectors. This might be as simple as having ``similar'' parts of speech like noun and proper noun are encoded as numbers that are close to each other.

\subsection{Clustering}
To disambiguate the various word senses for a particular word, we can extract the features of each instance of the word and cluster the generated feature vectors. Hopefully, the different word senses will create distinct clusters in the data and each cluster will be assigned a different word sense. Note that this by itself will not provide insight into what the word senses are, only that the word senses are different. 

Because we do not know how many different word senses a word might have in advance, we must pick our clustering method in a way so that it can pick the number of clusters on its own. To do this, we can either use a clustering algorithm that does not require us to specify a number of clusters at all (e.g., DBSCAN\footnote{https://www.aaai.org/Papers/KDD/1996/KDD96-037.pdf}) or we can pick a standard clustering algorithm like $k$-means, restrict the number of clusters to a particular reasonable range ($[1,n]$, where $n$ is the maximum number of word senses that we believe a word will have), and picking the value that optimizes some performance measure like the Bayesian Information Criterion (BIC)\footnote{https://www.jstor.org/stable/2958889}. The plan is to try multiple approaches and compare their performances.

\subsection{Annotation}
Once the instances of each word have been clustered, we can assign word senses to each cluster, then annotate the input data in a way so that instances with different word senses are considered separate. This can be as simple as assigning a number to each word sense and appending the corresponding number to the end of each word, e.g. ``apple'' (the fruit) could become ``apple0'' and ``Apple'' (the company) could become ``Apple1''. As mentioned earlier, the methodology here would not infer the meanings ``fruit'' and ``company'' themselves but instead just determine that these two word senses are distinct from each other.

\subsection{Evaluation}
There are a multiple approaches we can take for evaluation. First, we can take a dataset labeled for supervised word sense disambiguation and use them to evaluate the performance of the clustering algorithm using standard measures like V-measure\footnote{http://www.aclweb.org/anthology/D07-1043}. Schutze~\shortcite{schutze92context} also suggests a way to do this without labeled data where one artificially creates ambiguities by merging pairs of words and testing the model's ability to determine what the original word was. For example, all instances of ``train'' and ``tennis'' could be replaced with ``traintennis'' and the model is tasked with determine which instances of ``traintennis'' were originally ``train'' and which ones were originallly ``tennis''. We can generalize this method by merging an arbitrary number of words. 

We can also view our model as a preprocessing step to a larger task - this means that we can evaluate our model by seeing if annotating the data with word senses first improves performance on some other task.  

\bibliography{project_checkpoint2}
\bibliographystyle{naaclhlt2016}


\end{document}